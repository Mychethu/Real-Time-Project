# Real Time Sign Language Recognition System

## ğŸš€ Project Overview  
This project implements a real-time sign language recognition system using Python and computer vision. The system captures input via webcam, preprocesses hand gestures, and uses a trained model to recognize sign language symbols and translate them into text.  


## ğŸ§© Features  
- Real-time capture of hand gestures via webcam  
- Pre-processing of gesture images for clarity and consistency  
- Deep-learning model trained for sign language recognition  
- Text output translation of recognized gestures  
- Login/signup modules for user management (if applicable)  
- Modular code structure: data collection â†’ training â†’ inference  


## ğŸ› ï¸ Tech Stack  
- **Language**: Python  
- **Libraries & Frameworks**: OpenCV, TensorFlow/Keras, NumPy, pandas  
- **Model**: .h5 model file included (trained on custom dataset)  
- **Additional Tools**: package.json + package-lock.json (for any JS tools used)  

## ğŸ“‚ Repository Structure  
Real-Time-Project
â”‚
â”œâ”€ datacollection.py # Script to collect hand gesture images
â”œâ”€ train_model.h5 # Trained model file
â”œâ”€ final.py # Inference script for real-time recognition
â”œâ”€ login_page.py # User login module
â”œâ”€ signup_page.py # User signup module
â”œâ”€ home.py / home1.py # Main UI modules
â”œâ”€ test.py # Test script
â”œâ”€ labels1.txt # Label definitions for gestures
â”œâ”€ package.json # Project dependencies (if using JS)
â”œâ”€ package-lock.json
â””â”€ pycache/ # Python cache folder
## ğŸ“Œ Setup Instructions  
1. Clone the repository:  
   ```bash
   git clone https://github.com/Mychethu/Real-Time-Project.git
   cd Real-Time-Project

##ğŸ“‹ Future Improvements

*Expand dataset for more gesture classes
*Improve model accuracy and speed (e.g., using MobileNet)
*Integrate speech synthesis (convert recognized text into voice)
*Add GUI web interface or mobile app
*Add logging and user-profiles to track usage
